# NCCL åˆ†å¸ƒå¼é€šä¿¡æµ‹è¯•å¥—ä»¶

## 1. æ¦‚è¿°

æœ¬ç›®å½•æä¾›äº†å®Œæ•´çš„ NCCL (NVIDIA Collective Communication Library) åˆ†å¸ƒå¼é€šä¿¡æµ‹è¯•è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå•èŠ‚ç‚¹å’Œå¤šèŠ‚ç‚¹çš„ GPU é€šä¿¡æ€§èƒ½æµ‹è¯•ï¼ŒåŒ…å«å®¹å™¨åŒ–éƒ¨ç½²å’ŒåŸç”Ÿç¯å¢ƒéƒ¨ç½²ä¸¤ç§æ–¹å¼ã€‚

### 1.1 PXN æ¨¡å¼æ”¯æŒ

æœ¬æµ‹è¯•å¥—ä»¶ç°å·²å…¨é¢æ”¯æŒ **PXN (é«˜æ€§èƒ½å¤šèŠ‚ç‚¹é€šä¿¡) æ¨¡å¼**ï¼Œæä¾›é’ˆå¯¹å¤šèŠ‚ç‚¹ç¯å¢ƒä¼˜åŒ–çš„é«˜æ€§èƒ½é€šä¿¡è§£å†³æ–¹æ¡ˆï¼š

- **ä¸“ä¸ºå¤šèŠ‚ç‚¹ä¼˜åŒ–**ï¼šé’ˆå¯¹å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯è®¾è®¡
- **ä¸‰ç§ä¼˜åŒ–çº§åˆ«**ï¼šä¿å®ˆã€å¹³è¡¡ã€æ¿€è¿›æ¨¡å¼ï¼Œæ»¡è¶³ä¸åŒæ€§èƒ½éœ€æ±‚
- **æ™ºèƒ½ç½‘ç»œæ£€æµ‹**ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç½‘ç»œé…ç½®å’Œé€šä¿¡è·¯å¾„
- **è¯¦ç»†æ€§èƒ½åˆ†æ**ï¼šæä¾› PXN æ¨¡å¼ä¸“ç”¨çš„æ€§èƒ½æŒ‡æ ‡å’Œä¼˜åŒ–å»ºè®®
- **å…¨æ ˆæ”¯æŒ**ï¼šå®¹å™¨åŒ–ã€å¤šèŠ‚ç‚¹åŸç”Ÿã€Kubernetes éƒ¨ç½²å…¨é¢æ”¯æŒ

## 2. æ–‡ä»¶ç»“æ„

```text
nccl/
â”œâ”€â”€ ğŸ”§ æ ¸å¿ƒæµ‹è¯•å·¥å…·
â”‚   â”œâ”€â”€ nccl_benchmark.sh          # ä¸»è¦çš„ NCCL æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬ (æ”¯æŒ PXN æ¨¡å¼)
â”‚   â””â”€â”€ nccl_python_template.py    # Python æµ‹è¯•æ¨¡æ¿è„šæœ¬
â”œâ”€â”€ ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²
â”‚   â”œâ”€â”€ Dockerfile                 # NCCL æµ‹è¯•å®¹å™¨é•œåƒå®šä¹‰
â”‚   â””â”€â”€ nccl_container_manager.sh  # å®¹å™¨åŒ–æµ‹è¯•ç®¡ç†è„šæœ¬ (æ”¯æŒ PXN å¤šèŠ‚ç‚¹)
â”œâ”€â”€ ğŸŒ å¤šèŠ‚ç‚¹éƒ¨ç½²
â”‚   â”œâ”€â”€ nccl_multinode_launcher.sh # åŸç”Ÿå¤šèŠ‚ç‚¹æµ‹è¯•å¯åŠ¨å™¨ (æ”¯æŒ PXN æ¨¡å¼)
â”‚   â””â”€â”€ k8s/                       # Kubernetes å¤šèŠ‚ç‚¹éƒ¨ç½²æ–¹æ¡ˆ
â”‚       â”œâ”€â”€ deploy.sh              # Kubernetes éƒ¨ç½²ç®¡ç†è„šæœ¬ (æ”¯æŒ PXN æ¨¡å¼)
â”‚       â”œâ”€â”€ nccl-multinode-job.yaml # NCCL å¤šèŠ‚ç‚¹ Job é…ç½®
â”‚       â”œâ”€â”€ nccl-service.yaml      # NCCL æœåŠ¡é…ç½®
â”‚       â”œâ”€â”€ nccl-configmap.yaml    # NCCL é…ç½®æ˜ å°„
â”‚       â””â”€â”€ README.md              # Kubernetes éƒ¨ç½²æŒ‡å—
â”œâ”€â”€ ğŸš€ PXN æ¨¡å¼ä¸“ç”¨
â”‚   â”œâ”€â”€ demo_pxn_mode.sh           # PXN æ¨¡å¼æ¼”ç¤ºè„šæœ¬
â”‚   â”œâ”€â”€ PXN_MODE_GUIDE.md          # PXN æ¨¡å¼è¯¦ç»†æŒ‡å—
â”‚   â””â”€â”€ test_pxn_integration.sh    # PXN é›†æˆæµ‹è¯•è„šæœ¬
â”œâ”€â”€ ğŸ” è¯Šæ–­å·¥å…·
â”‚   â””â”€â”€ gpu_topology_detector.sh   # GPU æ‹“æ‰‘æ£€æµ‹å·¥å…·
â”œâ”€â”€ ğŸ“š é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ requirements.txt           # Python ä¾èµ–åŒ…é…ç½®
â”‚   â””â”€â”€ tutorial.md               # è¯¦ç»†ä½¿ç”¨æ•™ç¨‹å’Œæœ€ä½³å®è·µ
â””â”€â”€ ğŸ“ æµ‹è¯•æ•°æ®
    â””â”€â”€ test/                      # æµ‹è¯•è„šæœ¬å’Œæ•°æ® (åŒ…å« PXN æµ‹è¯•å¥—ä»¶)
        â”œâ”€â”€ test_pxn_mode.sh       # PXN æ¨¡å¼åŠŸèƒ½æµ‹è¯•
        â””â”€â”€ run_all_tests.sh       # å…¨å¥—æµ‹è¯•è¿è¡Œå™¨ (åŒ…å« PXN æµ‹è¯•)
```

## 3. æ ¸å¿ƒç»„ä»¶ä»‹ç»

### 3.1 æ ¸å¿ƒæµ‹è¯•å·¥å…·

#### 3.1.1 `nccl_benchmark.sh`

ä¸»è¦çš„ NCCL æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬ï¼Œæä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š

- **å¤šç½‘ç»œåç«¯æ”¯æŒ**ï¼šNVLinkã€InfiniBandã€Ethernetã€Socketã€**PXN**
- **PXN æ¨¡å¼ä¼˜åŒ–**ï¼šä¸“ä¸ºå¤šèŠ‚ç‚¹é«˜æ€§èƒ½é€šä¿¡è®¾è®¡çš„ä¼˜åŒ–æ¨¡å¼
- **ä¸‰ç§ä¼˜åŒ–çº§åˆ«**ï¼š
  - `conservative`: ä¿å®ˆæ¨¡å¼ï¼Œç¨³å®šæ€§ä¼˜å…ˆ
  - `balanced`: å¹³è¡¡æ¨¡å¼ï¼Œæ€§èƒ½ä¸ç¨³å®šæ€§å…¼é¡¾ (é»˜è®¤)
  - `aggressive`: æ¿€è¿›æ¨¡å¼ï¼Œæœ€å¤§æ€§èƒ½ä¼˜åŒ–
- **è‡ªåŠ¨è·¯å¾„æ£€æµ‹**ï¼šæ™ºèƒ½é€‰æ‹©æœ€ä½³é€šä¿¡è·¯å¾„ï¼Œæ”¯æŒ PXN è‡ªåŠ¨æ£€æµ‹
- **æ€§èƒ½åˆ†æ**ï¼šå»¶è¿Ÿã€å¸¦å®½ã€ååé‡ç­‰è¯¦ç»†æŒ‡æ ‡ï¼ŒåŒ…å« PXN ä¸“ç”¨æŒ‡æ ‡
- **ç¯å¢ƒéªŒè¯**ï¼šè‡ªåŠ¨æ£€æŸ¥ä¾èµ–å’Œé…ç½®ï¼ŒåŒ…å« PXN ç¯å¢ƒéªŒè¯

#### 3.1.2 `nccl_python_template.py`

åŸºäº PyTorch çš„åˆ†å¸ƒå¼æµ‹è¯•æ¨¡æ¿ï¼š

- **çµæ´»é…ç½®**ï¼šæ”¯æŒè‡ªå®šä¹‰å¼ é‡å¤§å°å’Œæµ‹è¯•æ—¶é•¿
- **è¯¦ç»†è¾“å‡º**ï¼šæä¾›å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡å’Œç»Ÿè®¡ä¿¡æ¯
- **å®¹å™¨å‹å¥½**ï¼šå¯åœ¨å®¹å™¨ç¯å¢ƒä¸­ç›´æ¥è¿è¡Œ

### 3.2 å®¹å™¨åŒ–éƒ¨ç½²

#### 3.2.1 `Dockerfile`

ä¼˜åŒ–çš„ NCCL æµ‹è¯•å®¹å™¨é•œåƒï¼š

- **åŸºç¡€é•œåƒ**ï¼šNVIDIA CUDA å®˜æ–¹é•œåƒ
- **é¢„è£…ä¾èµ–**ï¼šPyTorchã€NCCLã€InfiniBand å·¥å…·
- **ç½‘ç»œä¼˜åŒ–**ï¼šGPUDirect RDMA å’Œç½‘ç»œé…ç½®

#### 3.2.2 `nccl_container_manager.sh`

å®¹å™¨åŒ–æµ‹è¯•ç®¡ç†è„šæœ¬ï¼Œç°å·²æ”¯æŒå¤šèŠ‚ç‚¹ PXN æ¨¡å¼ï¼š

- **è‡ªåŠ¨æ„å»º**ï¼šä¸€é”®æ„å»ºæµ‹è¯•é•œåƒ
- **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§ GPU å’Œç½‘ç»œé…ç½®
- **PXN å¤šèŠ‚ç‚¹æ”¯æŒ**ï¼šæ”¯æŒå®¹å™¨åŒ–çš„å¤šèŠ‚ç‚¹ PXN æµ‹è¯•
- **ä¼˜åŒ–çº§åˆ«é…ç½®**ï¼šæ”¯æŒ PXN ä¸‰ç§ä¼˜åŒ–çº§åˆ«
- **ä¸»ä»èŠ‚ç‚¹é…ç½®**ï¼šæ”¯æŒ `--master-addr`ã€`--master-port` å‚æ•°
- **äº¤äº’æ¨¡å¼**ï¼šæä¾›è°ƒè¯•å’Œå¼€å‘ç¯å¢ƒ
- **å•èŠ‚ç‚¹å…¼å®¹**ï¼šä¿æŒåŸæœ‰å•èŠ‚ç‚¹æµ‹è¯•åŠŸèƒ½

### 3.3 å¤šèŠ‚ç‚¹éƒ¨ç½²

#### 3.3.1 `nccl_multinode_launcher.sh`

åŸç”Ÿå¤šèŠ‚ç‚¹æµ‹è¯•å¯åŠ¨å™¨ï¼Œç°å·²å…¨é¢æ”¯æŒ PXN æ¨¡å¼ï¼š

- **ç®€åŒ–éƒ¨ç½²**ï¼šä¸€é”®å¯åŠ¨å¤šèŠ‚ç‚¹æµ‹è¯•
- **PXN æ¨¡å¼æ”¯æŒ**ï¼šå®Œæ•´çš„ PXN é«˜æ€§èƒ½é€šä¿¡æ”¯æŒ
- **æ™ºèƒ½ç½‘ç»œæ£€æµ‹**ï¼šé»˜è®¤ä½¿ç”¨ `auto` æ¨¡å¼ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç½‘ç»œé…ç½®
- **ä¼˜åŒ–çº§åˆ«é…ç½®**ï¼šæ”¯æŒ `--optimization` å‚æ•°é…ç½®ä¼˜åŒ–çº§åˆ«
- **ç¯å¢ƒæ£€æŸ¥**ï¼šè‡ªåŠ¨éªŒè¯é›†ç¾¤ç¯å¢ƒï¼ŒåŒ…å« PXN ç¯å¢ƒéªŒè¯
- **é…ç½®ç®¡ç†**ï¼šç»Ÿä¸€çš„èŠ‚ç‚¹é…ç½®ï¼Œæ”¯æŒ PXN å‚æ•°ä¼ é€’
- **åŸç”Ÿç¯å¢ƒ**ï¼šé€‚ç”¨äºä¼ ç»Ÿè£¸æœºéƒ¨ç½²

#### 3.3.2 Kubernetes å¤šèŠ‚ç‚¹éƒ¨ç½²æ–¹æ¡ˆ (`k8s/`)

ç°ä»£åŒ–çš„å®¹å™¨ç¼–æ’å¤šèŠ‚ç‚¹éƒ¨ç½²æ–¹æ¡ˆï¼š

**`deploy.sh`** - Kubernetes éƒ¨ç½²ç®¡ç†è„šæœ¬ï¼Œç°å·²æ”¯æŒ PXN æ¨¡å¼ï¼š

- **ä¸€é”®éƒ¨ç½²**ï¼šè‡ªåŠ¨åŒ– Kubernetes èµ„æºåˆ›å»º
- **PXN æ¨¡å¼æ”¯æŒ**ï¼šæ”¯æŒ `--network pxn` å‚æ•°å¯ç”¨ PXN æ¨¡å¼
- **ä¼˜åŒ–çº§åˆ«é…ç½®**ï¼šæ”¯æŒ `--optimization` å‚æ•°é…ç½®ä¼˜åŒ–çº§åˆ«
- **å‚æ•°é…ç½®**ï¼šæ”¯æŒè‡ªå®šä¹‰ GPU æ•°é‡ã€æµ‹è¯•å‚æ•°
- **çŠ¶æ€ç›‘æ§**ï¼šå®æ—¶æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€å’Œæµ‹è¯•è¿›åº¦
- **èµ„æºæ¸…ç†**ï¼šå®Œæ•´çš„èµ„æºç”Ÿå‘½å‘¨æœŸç®¡ç†

**`nccl-multinode-job.yaml`** - NCCL å¤šèŠ‚ç‚¹ Job é…ç½®ï¼š

- **å¹¶è¡Œæ‰§è¡Œ**ï¼šæ”¯æŒå¤šèŠ‚ç‚¹å¹¶è¡Œæµ‹è¯•
- **èµ„æºç®¡ç†**ï¼šGPU èµ„æºè¯·æ±‚å’Œé™åˆ¶
- **ç½‘ç»œé…ç½®**ï¼šHost Network å’Œ IPC é…ç½®
- **ç¯å¢ƒå˜é‡**ï¼šå®Œæ•´çš„ NCCL å‚æ•°é…ç½®

**`nccl-service.yaml`** - NCCL æœåŠ¡é…ç½®ï¼š

- **æœåŠ¡å‘ç°**ï¼šèŠ‚ç‚¹é—´é€šä¿¡æœåŠ¡
- **ç«¯å£ç®¡ç†**ï¼šMaster å’Œ Worker ç«¯å£é…ç½®
- **è´Ÿè½½å‡è¡¡**ï¼šé›†ç¾¤å†…éƒ¨é€šä¿¡ä¼˜åŒ–

**`nccl-configmap.yaml`** - NCCL é…ç½®æ˜ å°„ï¼š

- **å‚æ•°ç®¡ç†**ï¼šé›†ä¸­åŒ–çš„ NCCL ç¯å¢ƒå˜é‡é…ç½®
- **æµ‹è¯•é…ç½®**ï¼šæ•°æ®å¤§å°ã€æµ‹è¯•æ—¶é•¿ç­‰å‚æ•°
- **ç½‘ç»œä¼˜åŒ–**ï¼šInfiniBand å’Œç½‘ç»œåç«¯é…ç½®

**`README.md`** - Kubernetes éƒ¨ç½²æŒ‡å—ï¼š

- **å®Œæ•´æ•™ç¨‹**ï¼šä»å®‰è£…åˆ°éƒ¨ç½²çš„è¯¦ç»†æ­¥éª¤
- **é…ç½®è¯´æ˜**ï¼šå„ç§å‚æ•°å’Œé€‰é¡¹çš„è¯¦ç»†è§£é‡Š
- **æ•…éšœæ’é™¤**ï¼šå¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- **æœ€ä½³å®è·µ**ï¼šç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å»ºè®®

### 3.4 è¯Šæ–­å·¥å…·

#### 3.4.1 `gpu_topology_detector.sh`

GPU æ‹“æ‰‘æ£€æµ‹å·¥å…·ï¼š

- **ç¡¬ä»¶æ£€æµ‹**ï¼šGPU è¿æ¥ç±»å‹åˆ†æ (NVLink, PCIe P2P)
- **è·¯å¾„åˆ†æ**ï¼šNCCL é€šä¿¡è·¯å¾„ä¼˜å…ˆçº§
- **æ€§èƒ½å»ºè®®**ï¼šç½‘ç»œé…ç½®ä¼˜åŒ–å»ºè®®

### 3.5 é…ç½®æ–‡ä»¶

#### 3.5.1 `requirements.txt`

Python ä¾èµ–åŒ…é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«ï¼š

- PyTorch åŠç›¸å…³ç»„ä»¶
- NCCL æµ‹è¯•æ‰€éœ€çš„ Python åº“
- å®¹å™¨åŒ–éƒ¨ç½²ä¾èµ–

#### 3.5.2 `tutorial.md`

è¯¦ç»†ä½¿ç”¨æ•™ç¨‹ï¼ŒåŒ…å«ï¼š

- å®Œæ•´çš„å®‰è£…å’Œé…ç½®è¯´æ˜
- å•èŠ‚ç‚¹å’Œå¤šèŠ‚ç‚¹æµ‹è¯•è¯¦ç»†æ­¥éª¤
- æ€§èƒ½è°ƒä¼˜å’Œæ•…éšœæ’é™¤
- æœ€ä½³å®è·µå’Œå‚è€ƒèµ„æ–™

## 4. å‰ç½®æ¡ä»¶

### 4.1 ç¡¬ä»¶è¦æ±‚

- **GPU**: ä¸€ä¸ªæˆ–å¤šä¸ª NVIDIA GPU (æ”¯æŒ CUDA)
- **ç½‘ç»œ**: InfiniBand æˆ–é«˜é€Ÿä»¥å¤ªç½‘ (å¯é€‰ï¼Œç”¨äºå¤šèŠ‚ç‚¹æµ‹è¯•)
- **å†…å­˜**: å»ºè®® 16GB ä»¥ä¸Šç³»ç»Ÿå†…å­˜

### 4.2 è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 18.04+/CentOS 7+/RHEL 7+)
- **Docker**: ç”¨äºå®¹å™¨åŒ–éƒ¨ç½² (æ¨è)
- **NVIDIA Container Toolkit**: GPU å®¹å™¨æ”¯æŒ
- **Python 3.7+**: åŸç”Ÿç¯å¢ƒæµ‹è¯• (å¯é€‰)
- **Kubernetes**: ç”¨äºå¤šèŠ‚ç‚¹å®¹å™¨ç¼–æ’ (å¯é€‰ï¼Œæ¨èç”Ÿäº§ç¯å¢ƒ)
  - kubectl 1.20+
  - GPU Operator æˆ– NVIDIA Device Plugin

### 4.3 å¿«é€Ÿå®‰è£… (å®¹å™¨åŒ–éƒ¨ç½²)

```bash
# 1. å®‰è£… Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# 2. å®‰è£… NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# 3. éªŒè¯ GPU å®¹å™¨æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.0-base-ubuntu20.04 nvidia-smi
```

## 5. å¿«é€Ÿå¼€å§‹

### 5.1 æ„å»ºæµ‹è¯•ç¯å¢ƒ

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/nccl/

# æ„å»ºå®¹å™¨é•œåƒ
./nccl_container_manager.sh --build
```

### 5.2 è¿è¡Œæµ‹è¯•

#### 5.2.1 å•èŠ‚ç‚¹æµ‹è¯• (æ¨èæ–°æ‰‹)

```bash
# åŸºç¡€æ€§èƒ½æµ‹è¯•
./nccl_container_manager.sh --gpus all --size 100M --time 60

# PXN æ¨¡å¼å•èŠ‚ç‚¹æµ‹è¯•
./nccl_container_manager.sh --gpus all --size 100M --time 60 --network pxn --optimization balanced

# GPU æ‹“æ‰‘æ£€æµ‹
./gpu_topology_detector.sh
```

#### 5.2.2 å¤šèŠ‚ç‚¹æµ‹è¯•

> è¦å‡†å¤‡ python å’Œ nccl ä¾èµ–çš„ç›¸å…³ç¯å¢ƒã€‚

**æ–¹æ¡ˆä¸€ï¼šåŸç”Ÿå¤šèŠ‚ç‚¹éƒ¨ç½²:**

```bash
# æ ‡å‡†å¤šèŠ‚ç‚¹æµ‹è¯•
# åœ¨ Master èŠ‚ç‚¹ (192.168.1.100) ä¸Šæ‰§è¡Œ
./nccl_multinode_launcher.sh 0 192.168.1.100 --world-size 4 --nproc-per-node 2

# åœ¨ Worker èŠ‚ç‚¹ (192.168.1.101) ä¸Šæ‰§è¡Œ  
./nccl_multinode_launcher.sh 1 192.168.1.100 --world-size 4 --nproc-per-node 2

# PXN æ¨¡å¼å¤šèŠ‚ç‚¹æµ‹è¯•ï¼ˆé«˜æ€§èƒ½ï¼‰
# åœ¨ Master èŠ‚ç‚¹ä¸Šæ‰§è¡Œ
./nccl_multinode_launcher.sh 0 192.168.1.100 --world-size 4 --nproc-per-node 2 --network pxn --optimization aggressive

# åœ¨ Worker èŠ‚ç‚¹ä¸Šæ‰§è¡Œ
./nccl_multinode_launcher.sh 1 192.168.1.100 --world-size 4 --nproc-per-node 2 --network pxn --optimization aggressive
```

**æ–¹æ¡ˆäºŒï¼šKubernetes å¤šèŠ‚ç‚¹éƒ¨ç½²ï¼ˆæ¨èï¼‰:**

```bash
# è¿›å…¥ Kubernetes é…ç½®ç›®å½•
cd k8s/

# å¿«é€Ÿéƒ¨ç½²ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
./deploy.sh deploy

# è‡ªå®šä¹‰éƒ¨ç½²
./deploy.sh deploy --gpus 4 --test-size 1G --test-duration 120

# PXN æ¨¡å¼éƒ¨ç½²ï¼ˆé«˜æ€§èƒ½å¤šèŠ‚ç‚¹ï¼‰
./deploy.sh deploy --gpus 4 --test-size 1G --test-duration 120 --network pxn --optimization balanced

# PXN æ¿€è¿›æ¨¡å¼éƒ¨ç½²ï¼ˆæœ€å¤§æ€§èƒ½ï¼‰
./deploy.sh deploy --gpus 8 --test-size 2G --test-duration 180 --network pxn --optimization aggressive

# æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
./deploy.sh status

# æŸ¥çœ‹æµ‹è¯•æ—¥å¿—
./deploy.sh logs

# æ¸…ç†èµ„æº
./deploy.sh cleanup
```

### 5.3 æŸ¥çœ‹ç»“æœ

æµ‹è¯•å®Œæˆåï¼ŒæŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶ï¼š

- æ€§èƒ½æµ‹è¯•æŠ¥å‘Š
- GPU æ‹“æ‰‘åˆ†æ
- ç½‘ç»œé…ç½®å»ºè®®

## 6. ä½¿ç”¨åœºæ™¯

### 6.1 æ€§èƒ½åŸºå‡†æµ‹è¯•

- å»ºç«‹ GPU é€šä¿¡æ€§èƒ½åŸºçº¿
- éªŒè¯ç¡¬ä»¶é…ç½®æ•ˆæœ
- å¯¹æ¯”ä¸åŒç½‘ç»œåç«¯æ€§èƒ½
- **PXN æ¨¡å¼æ€§èƒ½è¯„ä¼°**ï¼šæµ‹è¯•é«˜æ€§èƒ½å¤šèŠ‚ç‚¹é€šä¿¡ä¼˜åŒ–æ•ˆæœ
- **ä¼˜åŒ–çº§åˆ«å¯¹æ¯”**ï¼šè¯„ä¼° conservativeã€balancedã€aggressive ä¸‰ç§ä¼˜åŒ–çº§åˆ«çš„æ€§èƒ½å·®å¼‚

### 6.2 ç¯å¢ƒéªŒè¯

- éªŒè¯ NCCL ç¯å¢ƒé…ç½®
- æ£€æŸ¥ GPU æ‹“æ‰‘ç»“æ„
- è¯Šæ–­ç½‘ç»œè¿æ¥é—®é¢˜
- **PXN ç¯å¢ƒæ£€æµ‹**ï¼šéªŒè¯ PXN æ¨¡å¼çš„ç½‘ç»œç¯å¢ƒå’Œé…ç½®
- **æ™ºèƒ½ç½‘ç»œæ£€æµ‹**ï¼šè‡ªåŠ¨æ£€æµ‹æœ€é€‚åˆçš„ç½‘ç»œåç«¯ï¼ˆInfiniBandã€ä»¥å¤ªç½‘ç­‰ï¼‰

### 6.3 ç”Ÿäº§éƒ¨ç½²å‡†å¤‡

- å¤šèŠ‚ç‚¹é›†ç¾¤æ€§èƒ½éªŒè¯
- å®¹å™¨åŒ–éƒ¨ç½²æµ‹è¯•
- åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒå‡†å¤‡
- Kubernetes é›†ç¾¤ NCCL æ€§èƒ½éªŒè¯
- äº‘åŸç”Ÿç¯å¢ƒé€‚é…æµ‹è¯•
- **PXN æ¨¡å¼ç”Ÿäº§éƒ¨ç½²**ï¼šå¤§è§„æ¨¡å¤šèŠ‚ç‚¹é›†ç¾¤çš„ PXN æ¨¡å¼éƒ¨ç½²å’Œä¼˜åŒ–
- **å¤šèŠ‚ç‚¹ PXN è°ƒä¼˜**ï¼šé’ˆå¯¹ä¸åŒç¡¬ä»¶é…ç½®çš„ PXN ä¼˜åŒ–çº§åˆ«é€‰æ‹©

### 6.4 äº‘åŸç”Ÿéƒ¨ç½²

- Kubernetes é›†ç¾¤ GPU é€šä¿¡æµ‹è¯•
- å®¹å™¨ç¼–æ’ç¯å¢ƒæ€§èƒ½åŸºå‡†
- å¤šç§Ÿæˆ·ç¯å¢ƒéš”ç¦»éªŒè¯
- è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œç›‘æ§
- **äº‘åŸç”Ÿ PXN éƒ¨ç½²**ï¼šKubernetes ç¯å¢ƒä¸‹çš„ PXN æ¨¡å¼è‡ªåŠ¨åŒ–éƒ¨ç½²
- **PXN å®¹å™¨ç¼–æ’**ï¼šæ”¯æŒ PXN æ¨¡å¼çš„å®¹å™¨åŒ–å¤šèŠ‚ç‚¹é€šä¿¡ä¼˜åŒ–

## 7. è¯¦ç»†æ–‡æ¡£

- **[è¯¦ç»†ä½¿ç”¨æ•™ç¨‹](./tutorial.md)** - å®Œæ•´çš„å®‰è£…ã€é…ç½®å’Œä½¿ç”¨è¯´æ˜
- **[Kubernetes éƒ¨ç½²æŒ‡å—](./k8s/README.md)** - Kubernetes å¤šèŠ‚ç‚¹éƒ¨ç½²è¯¦ç»†æ•™ç¨‹
- **[æ•…éšœæ’é™¤](./tutorial.md#æ•…éšœæ’é™¤)** - å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
- **[æ€§èƒ½è°ƒä¼˜](./tutorial.md#æ€§èƒ½è°ƒä¼˜)** - æœ€ä½³å®è·µå’Œä¼˜åŒ–å»ºè®®

## 8. å‚è€ƒèµ„æ–™

- [NVIDIA Container Toolkit æ–‡æ¡£](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)
- [NCCL å®˜æ–¹æ–‡æ¡£](https://docs.nvidia.com/deeplearning/nccl/)
- [PyTorch åˆ†å¸ƒå¼è®­ç»ƒ](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
- [Kubernetes GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/)
- [Kubernetes å®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
